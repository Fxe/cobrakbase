{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efe943dc-06ec-43e8-a99a-5f2bcade50c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cobrakbase 0.2.8\n"
     ]
    }
   ],
   "source": [
    "import cobrakbase\n",
    "%run ../../cobrakbase/AbstractHandleClient.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9777db40-fff8-42c7-aeca-0d744ca6dd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc258640-3a61-446b-873f-7d8239f2ed66",
   "metadata": {},
   "outputs": [],
   "source": [
    "kbase = cobrakbase.KBaseAPI('K6MO26MQ355EUTJCVPFYIXER4DRS7BWO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf1d79d9-604b-4d2c-ad70-2e813eb8eb7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/fliu/workspace/jupyter/python3/cobrakbase/examples/random_stuff\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63a72e8-62fd-4df9-8978-779f5efb28fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "723111a6-f248-44af-996c-77e1fbbf4c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShockException(Exception):\n",
    "    pass\n",
    "\n",
    "def download_file_from_kbase(token, file_id, file_path, is_handle_ref = 1,\n",
    "    handle_url = \"https://kbase.us/services/handle_service\",\n",
    "    shock_url = \"https://kbase.us/services/shock-api\",\n",
    "):\n",
    "    headers = {'Authorization': 'OAuth ' + token}  \n",
    "    \n",
    "    if is_handle_ref == 1:\n",
    "        hs = AbstractHandle(handle_url, token=token)\n",
    "        handles = hs.hids_to_handles([file_id])\n",
    "        file_id = handles[0]['id']\n",
    "    print(file_path)\n",
    "    if not os.path.exists(file_path):\n",
    "        try:\n",
    "            os.makedirs(file_path)\n",
    "        except OSError as exc:\n",
    "            print(exc)\n",
    "            raise\n",
    "    elif not os.path.isdir(file_path):\n",
    "        raise ShockException(\"file_path: %s must be directory\", file_path)\n",
    "    \n",
    "    node_url = shock_url + '/node/' + file_id\n",
    "    r = requests.get(node_url, headers=headers, allow_redirects=True)\n",
    "    print(r)\n",
    "    #return r\n",
    "    if not r.ok:\n",
    "        errtxt = ('Error downloading file from shock ' +\n",
    "          'node {}: ').format(file_id)\n",
    "        try:\n",
    "            err = json.loads(response.content)['error'][0]\n",
    "        except Exception:\n",
    "            # this means shock is down or not responding.\n",
    "            log(\"Couldn't parse response error content from Shock: \" +\n",
    "                response.content)\n",
    "            response.raise_for_status()\n",
    "        raise ShockException(errtxt + str(err))\n",
    "    \n",
    "    resp_obj = r.json()\n",
    "    size = resp_obj['data']['file']['size']\n",
    "    if not size:\n",
    "        raise ShockException('Node {} has no file'.format(shock_id))\n",
    "    \n",
    "    node_file_name = resp_obj['data']['file']['name']\n",
    "    attributes = resp_obj['data']['attributes']\n",
    "    if os.path.isdir(file_path):\n",
    "        file_path = os.path.join(file_path, node_file_name)\n",
    "    with open(file_path, 'wb') as fhandle:\n",
    "        with requests.get(node_url + '?download_raw', stream=True,headers=headers, allow_redirects=True) as r:\n",
    "            if not r.ok:\n",
    "                errtxt = ('Error downloading file from shock ' +\n",
    "                  'node {}: ').format(file_id)\n",
    "                try:\n",
    "                    err = json.loads(response.content)['error'][0]\n",
    "                except Exception:\n",
    "                    # this means shock is down or not responding.\n",
    "                    log(\"Couldn't parse response error content from Shock: \" +\n",
    "                        response.content)\n",
    "                    response.raise_for_status()\n",
    "                raise ShockException(errtxt + str(err))\n",
    "            for chunk in r.iter_content(1024):\n",
    "                if not chunk:\n",
    "                    break\n",
    "                fhandle.write(chunk)\n",
    "    return file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5af4da35-09d8-4d96-8a78-4a50fd73e01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "metagenome_assembly = kbase.get_from_ws('ANME_2C_COP2.fa_assembly.meta.RAST', 92287)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ba1887a-560c-4c68-b4bd-ae9774e5e768",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'KBH_5593329'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metagenome_assembly.features_handle_ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5de63903-5cea-4d0a-bbc4-c6417a7fdbc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/fliu/workspace/jupyter/python3/cobrakbase/examples/random_stuff\n",
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "#print(download_file_from_kbase(\"<TOKEN>\",file_id = \"KBH_5023369\",file_path = \"/Users/chenry/\"))\n",
    "response = download_file_from_kbase(\"K6MO26MQ355EUTJCVPFYIXER4DRS7BWO\", file_id = \"KBH_5593329\", file_path = \"/home/fliu/workspace/jupyter/python3/cobrakbase/examples/random_stuff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8f96c0ea-84b8-40b2-ba92-b785108df0d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "39dd57b6-bc98-48eb-9789-6aa1e3cb445c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m Raises :class:`HTTPError`, if one occurred.\n",
       "\u001b[0;31mFile:\u001b[0m      /usr/local/lib/python3.8/site-packages/requests/models.py\n",
       "\u001b[0;31mType:\u001b[0m      method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?response.raise_for_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "13980a70-0517-4254-9195-5661ca897074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/fliu/workspace/jupyter/python3/cobrakbase/examples/random_stuff\n",
      "[Errno 17] File exists: '/home/fliu/workspace/jupyter/python3/cobrakbase/examples/random_stuff'\n",
      "<Response [200]>\n",
      "/home/fliu/workspace/jupyter/python3/cobrakbase/examples/random_stuff/ANME_2C_COP2.fa_assembly.meta.RAST_features.json.gz\n"
     ]
    }
   ],
   "source": [
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db7e09e4-8277-4bcc-ad18-097ab12348be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "46c0af40-9ab5-4af7-9016-402e7d9543a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "f = gzip.open('ANME_2C_COP2.fa_assembly.meta.RAST_features.json.gz','rb')\n",
    "file_content = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "922297a0-a437-4c47-888e-66dafc1d7bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "data = json.loads(file_content.decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "29bfe6c4-f2aa-4f8c-a003-5001f4abe35c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4790"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "122cbb27-d4c9-438c-814f-2021c0df4108",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CDS', 'gene'}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{o['type'] for o in data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d8451a2a-60ad-4999-a20d-8beb080500d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "classif = kbase.get_from_ws('ArcheaCLF_decision_tree_classifier_entropy', 77223)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0498910e-5bab-45a1-a7d4-295c3b83d3ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['attribute_data', 'attribute_type', 'class_list_mapping', 'classifier_data', 'classifier_description', 'classifier_handle_ref', 'classifier_id', 'classifier_name', 'classifier_type', 'lib_name', 'number_of_attributes', 'number_of_genomes', 'training_set_ref', 'exclude_dict', 'data_keys', 'info', 'data', 'provenance', 'path', 'creator', 'orig_wsid', 'created', 'epoch', 'refs', 'copied', 'copy_source_inaccessible'])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classif.data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "66587e35-0e0b-4ba8-82b5-505c728f0047",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'KBH_4997360'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classif.data['classifier_handle_ref']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1ae6163a-a28a-4953-97e2-8020d753cf46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/fliu/workspace/jupyter/python3/cobrakbase/examples/random_stuff\n",
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "response = download_file_from_kbase(\"K6MO26MQ355EUTJCVPFYIXER4DRS7BWO\", file_id = \"KBH_4997360\", file_path = \"/home/fliu/workspace/jupyter/python3/cobrakbase/examples/random_stuff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e816aa2-05a7-4115-95e4-9e4e25bd9699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23.2\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import sklearn\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e576f64-6642-4991-aaab-fcda8229b535",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ArcheaCLF_decision_tree_classifier_entropy.pickle', 'rb') as fh:\n",
    "    current_categorizer = pickle.load(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b6b3edaf-4679-47e8-af30-99a3f9a60eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7d149295-bf2d-4f30-b87a-a7c8b1615d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "genome_object_data = kbase.ws_client.get_objects2({'objects': [{'ref': '78503/3731/1'}]})['data'][0]['data']\n",
    "genome1 = kbase.get_from_ws('78503/3731/1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f1b6f214-8210-45f7-949a-6aff1676b2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = createIndicatorMatrixX(['78503/3731/1'], kbase.ws_client, master_role_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "2b94bc06-4af7-4ee9-a480-983203715f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features\n",
      "495 495\n"
     ]
    }
   ],
   "source": [
    "def get_list_functional_roles(genome_object_data):\n",
    "    list_functional_roles = {}\n",
    "\n",
    "    # figure out where functional roles are kept\n",
    "    keys_location = genome_object_data.keys()\n",
    "    if \"features\" in keys_location:\n",
    "        location_of_functional_roles = genome_object_data[\"features\"]\n",
    "        print('features')\n",
    "    elif \"non_coding_features\" in keys_location:\n",
    "        location_of_functional_roles = genome_object_data[\"non_coding_features\"]\n",
    "        print('non_coding_features')\n",
    "    elif \"cdss\" in keys_location:\n",
    "        location_of_functional_roles = genome_object_data[\"cdss\"]\n",
    "        print('cdss')\n",
    "    else:\n",
    "        raise ValueError(\"The functional roles are not under features, non_coding_features, or cdss...\")\n",
    "\n",
    "    # either the functional roles are under function or functions (really stupid...)\n",
    "    keys_function = location_of_functional_roles[0].keys()\n",
    "    \n",
    "    function_str = \"function\" if \"function\" in keys_function else \"functions\"\n",
    "    for functional_role in location_of_functional_roles:\n",
    "        try:\n",
    "            for role_to_insert in functional_role[function_str]:\n",
    "                if \" @ \" in role_to_insert:\n",
    "                    list_functional_roles[functional_role['id']] = role_to_insert.split(\" @ \")\n",
    "                elif \" / \" in role_to_insert:\n",
    "                    list_functional_roles[functional_role['id']] = role_to_insert.split(\" / \")\n",
    "                elif \"; \" in role_to_insert:\n",
    "                    list_functional_roles[functional_role['id']] = role_to_insert.split(\"; \")\n",
    "                elif 'hypothetical protein' in role_to_insert:\n",
    "                    pass\n",
    "                else:\n",
    "                    list_functional_roles[functional_role['id']] = {role_to_insert}\n",
    "        except KeyError as e:\n",
    "            # print(\"this is funcitonal role\")\n",
    "            # print(functional_role)\n",
    "            # print(\"this is list_functional_roles\")\n",
    "            # print(list_functional_roles)\n",
    "\n",
    "            # print(\"apparently some function list just don't have functions...\")\n",
    "            # ^^ this makes no sense...\n",
    "            pass\n",
    "\n",
    "    return list_functional_roles\n",
    "list_functional_roles = get_list_functional_roles(genome_object_data)\n",
    "print(len(list_functional_roles), len(set(list_functional_roles)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "50b8b3e7-21b0-45b1-adb7-a1019e0c9aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#list(filter(lambda x: x['id'] == 'K645_RS02840', genome_object_data['features']))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ef5b11d0-e2ea-4e46-a4ea-5e9c996f73ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#genome1.features.K645_RS02840.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "3e9b886a-7cd4-4357-a48e-51cf80a83c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K645_RS00510 {'Bacterial checkpoint controller DisA with nucleotide-binding domain'} ######## {'Diadenylate cyclase spyDAC', 'Bacterial checkpoint controller DisA with nucleotide-binding domain'}\n",
      "K645_RS00585 {'Succinate-semialdehyde dehydrogenase [NADP+] (EC 1.2.1.79)'} ######## {'Succinate-semialdehyde dehydrogenase [NAD] (EC 1.2.1.24)', 'Succinate-semialdehyde dehydrogenase [NADP+] (EC 1.2.1.79)'}\n",
      "K645_RS00610 {'NADP-specific glutamate dehydrogenase (EC 1.4.1.4)'} ######## {'NAD-specific glutamate dehydrogenase (EC 1.4.1.2)', 'NADP-specific glutamate dehydrogenase (EC 1.4.1.4)'}\n",
      "K645_RS02840 {'Molybdenum transport protein, putative'} ######## {'ABC-type Fe3+ transport system protein', 'Molybdenum transport protein, putative'}\n",
      "K645_RS02945 {'PhnP protein'} ######## {'PhnP protein', 'Metal-dependent hydrolases of the beta-lactamase superfamily I'}\n"
     ]
    }
   ],
   "source": [
    "for k in list_functional_roles:\n",
    "    if k in list_functional_roles2:\n",
    "        f1 = set(list_functional_roles[k])\n",
    "        f2 = set(list_functional_roles2[k])\n",
    "        if f1 != f2:\n",
    "            print(k, f1, '########', f2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "b3d27641-3816-46ef-b8af-7b00895adcc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "genome1.features.K645_RS02840.add_ontology_term('RAST', 'banada')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "afb7dfcc-c707-4669-a3d0-dd101b26cf4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'RAST': ['lol', 'banada']}"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genome1.features.K645_RS02840.ontology_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b5feac8c-83bd-480d-a283-808769e413d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rast.f1('K645_RS02840', genome1.features.K645_RS02840.seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "931ba282-7e6e-4f51-8080-64a4a9ba396a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import modelseedpy\n",
    "rast = modelseedpy.RastClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "94b7b5f5-800a-410e-b614-4653397079bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "538 538\n"
     ]
    }
   ],
   "source": [
    "list_functional_roles2 = {}\n",
    "for f in genome1.features:\n",
    "    if f.functions_unsplit != 'hypothetical protein':\n",
    "        list_functional_roles2[f.id] = f.functions\n",
    "print(len(list_functional_roles2), len(set(list_functional_roles2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "de1e08ce-2e89-4c91-a6e6-47f7a1599a3f",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-104-26059b3a5842>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mi2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_functional_roles2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist_functional_roles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mf2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist_functional_roles2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mf1\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mf2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "i1 = len(list_functional_roles)\n",
    "i2 = len(list_functional_roles2)\n",
    "for i in range(i1):\n",
    "    f1 = list_functional_roles[i]\n",
    "    f2 = list_functional_roles2[i]\n",
    "    if f1 != f2:\n",
    "        print(i, f1, '########', f2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "8d531612-419e-48f4-abcd-c6d2dba68d79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lol', 'banada']"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_list_functional_roles(genome, ontology_term):\n",
    "    list_functional_roles = []\n",
    "    for feature in genome.features:\n",
    "        if ontology_term in feature.ontology_terms:\n",
    "            list_functional_roles.extend(feature.ontology_terms[ontology_term])\n",
    "    return list_functional_roles\n",
    "get_list_functional_roles(genome1, 'RAST')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "4d8f4dc0-d798-45e3-b8a7-67515a374bb6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def createIndicatorMatrixX(genome_references, ws_client, master_role_list = None, ontology_term='RAST'):\n",
    "    ref_to_role = {}\n",
    "    if(master_role_list == None):\n",
    "        master_role_set = set()\n",
    "    for genome_ref in genome_references:\n",
    "        ref_to_role[genome_ref] = get_list_functional_roles(genome, ontology_term)\n",
    "\n",
    "        if master_role_list is None:\n",
    "            # keep updateing a set of all functional roles seen so far\n",
    "            master_role_set |= set(ref_to_role[genome_ref])\n",
    "\n",
    "    if(master_role_list == None):\n",
    "        #we are done looping over all genomes\n",
    "        master_role_list = sorted(list(master_role_set))\n",
    "\n",
    "        try:\n",
    "            master_role_list.remove('')\n",
    "        except:    \n",
    "            pass\n",
    "    ref_to_indication = {}\n",
    "\n",
    "    #make indicator rows for each \n",
    "    for genome_ref in genome_references:\n",
    "        set_functional_roles = set(ref_to_role[genome_ref])\n",
    "        matching_index = [i for i, role in enumerate(master_role_list) if role in set_functional_roles] \n",
    "\n",
    "        indicators = np.zeros(len(master_role_list))\n",
    "        try:\n",
    "            indicators[np.array(matching_index)] = 1\n",
    "        except (IndexError):\n",
    "            raise IndexError('The genomes or genomeSet that you have submitted wasn’t annotated using the \\\n",
    "                RAST annotation pipeline. Please annotate the genomes via ‘Annotate Microbial Genome’ app \\\n",
    "                (https://narrative.kbase.us/#appcatalog/app/RAST_SDK/reannotate_microbial_genome/release)or \\\n",
    "                genomeSets via Annotate Multiple Microbial Genomes’ app \\\n",
    "                (https://narrative.kbase.us/#appcatalog/app/RAST_SDK/reannotate_microbial_genomes/release) and \\\n",
    "                resubmit the RAST annotated genome/genomeSets into the Predict Phenotype app. (')\n",
    "        ref_to_indication[genome_ref] = indicators.astype(int)\n",
    "\n",
    "\n",
    "    indicator_matrix = pd.DataFrame.from_dict(data = ref_to_indication, orient='index', columns = master_role_list).reset_index().rename(columns={\"index\":\"Genome Reference\"})\n",
    "\n",
    "    return indicator_matrix, master_role_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d9a22d2d-0da4-4072-a35f-cb5f39c78b5f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def createIndicatorMatrix(self, uploaded_df, genome_attribute, master_role_list = None):\n",
    "    genome_references = uploaded_df[\"Genome Reference\"].to_list()\n",
    "    ref_to_role = {}\n",
    "    if(master_role_list == None):\n",
    "        master_role_set = set()\n",
    "\n",
    "    for genome_ref in genome_references:\n",
    "        genome_object_data = self.ws_client.get_objects2({'objects':[{'ref': genome_ref}]})['data'][0]['data']\n",
    "\n",
    "        #figure out where functional roles are kept\n",
    "        keys_location = genome_object_data.keys()\n",
    "        if (\"features\" in keys_location):\n",
    "            location_of_functional_roles = genome_object_data[\"features\"]\n",
    "\n",
    "        elif (\"non_coding_features\" in keys_location):\n",
    "            location_of_functional_roles = genome_object_data[\"non_coding_features\"]\n",
    "\n",
    "        elif (\"cdss\" in keys_location):\n",
    "            location_of_functional_roles = genome_object_data[\"cdss\"]\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"The functional roles are not under features, non_coding_features, or cdss...\")\n",
    "\n",
    "        #either the functional roles are under function or functions (really stupid...)\n",
    "        keys_function = location_of_functional_roles[0].keys()\n",
    "        function_str = \"function\" if \"function\" in keys_function else \"functions\"\n",
    "\n",
    "        list_functional_roles = []\n",
    "        for functional_role in location_of_functional_roles:\n",
    "            try:\n",
    "                role_to_insert = functional_role[function_str][0]\n",
    "                if \" @ \" in  role_to_insert:\n",
    "                    list_functional_roles.extend(role_to_insert.split(\" @ \"))\n",
    "                elif \" / \" in role_to_insert:\n",
    "                    list_functional_roles.extend(role_to_insert.split(\" / \"))\n",
    "                elif \"; \" in role_to_insert:\n",
    "                    list_functional_roles.extend(role_to_insert.split(\"; \"))\n",
    "                elif 'hypothetical protein' in role_to_insert:\n",
    "                    pass\n",
    "                else:\n",
    "                    list_functional_roles.append(role_to_insert)\n",
    "            except (KeyError):\n",
    "                # print(\"this is funcitonal role\")\n",
    "                # print(functional_role)\n",
    "                # print(\"this is list_functional_roles\")\n",
    "                # print(list_functional_roles)\n",
    "\n",
    "                #print(\"apparently some function list just don't have functions...\")\n",
    "                #^^ this makes no sense...\n",
    "                pass\n",
    "\n",
    "        #create a mapping from genome_ref to all of its functional roles\n",
    "        ref_to_role[genome_ref] = list_functional_roles\n",
    "\n",
    "        if(master_role_list == None):\n",
    "            #keep updateing a set of all functional roles seen so far\n",
    "            master_role_set = master_role_set.union(set(list_functional_roles))\n",
    "\n",
    "    if(master_role_list == None):\n",
    "        #we are done looping over all genomes\n",
    "        master_role_list = sorted(list(master_role_set))\n",
    "\n",
    "        try:\n",
    "            master_role_list.remove('')\n",
    "        except:    \n",
    "            pass\n",
    "    ref_to_indication = {}\n",
    "\n",
    "    #make indicator rows for each \n",
    "    for genome_ref in genome_references:\n",
    "        set_functional_roles = set(ref_to_role[genome_ref])\n",
    "        matching_index = [i for i, role in enumerate(master_role_list) if role in set_functional_roles] \n",
    "\n",
    "        indicators = np.zeros(len(master_role_list))\n",
    "        try:\n",
    "            indicators[np.array(matching_index)] = 1\n",
    "        except (IndexError):\n",
    "            raise IndexError('The genomes or genomeSet that you have submitted wasn’t annotated using the \\\n",
    "                RAST annotation pipeline. Please annotate the genomes via ‘Annotate Microbial Genome’ app \\\n",
    "                (https://narrative.kbase.us/#appcatalog/app/RAST_SDK/reannotate_microbial_genome/release)or \\\n",
    "                genomeSets via Annotate Multiple Microbial Genomes’ app \\\n",
    "                (https://narrative.kbase.us/#appcatalog/app/RAST_SDK/reannotate_microbial_genomes/release) and \\\n",
    "                resubmit the RAST annotated genome/genomeSets into the Predict Phenotype app. (')\n",
    "        ref_to_indication[genome_ref] = indicators.astype(int)\n",
    "\n",
    "\n",
    "    indicator_matrix = pd.DataFrame.from_dict(data = ref_to_indication, orient='index', columns = master_role_list).reset_index().rename(columns={\"index\":\"Genome Reference\"})\n",
    "\n",
    "    return (indicator_matrix, master_role_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c003f8be-d35d-40df-bb41-4dff65cf7f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "genome1 = kbase.get_from_ws('GCF_001051995.2.RAST', 'filipeliu:narrative_1606804059500')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "22f21bd0-da49-471c-85b5-8dd81129ff59",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_role_list = classif.attribute_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ad201b-ed4a-43a9-a235-64f5501d60d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d2169e69-4bb7-4cff-aedb-8811467dc062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight='balanced', criterion='entropy',\n",
       "                       max_depth=1, random_state=0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_categorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "99e43c74-6b8c-4df5-888a-3c7f368130fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get functional_roles and make indicator matrix\n",
    "# = self.createIndicatorMatrix(subset_uploaded_df, genome_attribute, master_role_list = master_role_list)\n",
    "(indicator_matrix, master_role_list) = res\n",
    "whole_X = indicator_matrix[master_role_list].values\n",
    "\n",
    "#Make Predictions on uploaded file\n",
    "predictions_numerical = current_categorizer.predict(whole_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0155f6d8-be33-47f9-a6f6-b916bf4c2278",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'N': 0, 'P': 1}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_list_mapping = classif.class_list_mapping\n",
    "class_list_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "12f7eaa2-c888-459d-b992-268110d5cdf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_map_class_list_mapping = {v: k for k, v in class_list_mapping.items()}\n",
    "predictions_phenotype = [] #map numerical to phenotype\n",
    "for numerical in predictions_numerical:\n",
    "    predictions_phenotype.append(inv_map_class_list_mapping[numerical])\n",
    "prediction_probabilities_ = current_categorizer.predict_proba(whole_X)\n",
    "prediction_probabilities = np.max(prediction_probabilities_, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e52dcd-5d43-4410-9d26-4caaaf147396",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d3de8f-73af-4b9b-9424-140af8be53ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76157a9f-aa9a-455a-8672-0383777cedd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12998/11/2 GramStainKNN"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
